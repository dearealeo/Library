name: Publish today Release

on:
  workflow_run:
    workflows: ["Update today Xinwen Lianbo"]
    types: [completed]
    branches: [main]
  workflow_dispatch:

concurrency:
  group: release-${{ github.ref }}
  cancel-in-progress: false

jobs:
  prepare:
    name: Prepare Release Data
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    outputs:
      date: ${{ steps.date.outputs.full_date }}
      year: ${{ steps.date.outputs.year }}
      month: ${{ steps.date.outputs.month }}
      day: ${{ steps.date.outputs.day }}
      workflows: ${{ steps.set-matrix.outputs.workflows }}
      should_proceed: ${{ steps.check-commits.outputs.should_proceed }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.ref }}

      - name: Get current date
        id: date
        run: |
          TZ=Asia/Shanghai date +'year=%y' >> $GITHUB_OUTPUT
          TZ=Asia/Shanghai date +'month=%m' >> $GITHUB_OUTPUT
          TZ=Asia/Shanghai date +'day=%d' >> $GITHUB_OUTPUT
          TZ=Asia/Shanghai date +'full_date=%Y-%m-%d' >> $GITHUB_OUTPUT

      - name: Check commits from all workflows in last 24 hours
        id: check-commits
        run: |
          COMMITS=$(git log --since="24 hours ago" --oneline)
          HAS_NEWS=$(echo "$COMMITS" | grep -c "feat(news): update" || echo "0")
          HAS_LAWS=$(echo "$COMMITS" | grep -c "feat(laws): update" || echo "0")
          HAS_RULESET=$(echo "$COMMITS" | grep -c "feat(ruleset): update" || echo "0")

          echo "News commits: $HAS_NEWS"
          echo "Laws commits: $HAS_LAWS"
          echo "Ruleset commits: $HAS_RULESET"

          if [[ $HAS_NEWS -gt 0 && $HAS_LAWS -gt 0 && $HAS_RULESET -gt 0 ]]; then
            echo "All required workflow commits found within the last 24 hours."
            echo "should_proceed=true" >> $GITHUB_OUTPUT
          else
            echo "Not all required workflow commits found within the last 24 hours."
            echo "should_proceed=false" >> $GITHUB_OUTPUT
          fi

      - name: Set workflow matrix
        id: set-matrix
        run: |
          echo "workflows=[\"国家法律法规数据库\",\"新闻联播\",\"Ruleset\"]" >> $GITHUB_OUTPUT

  build:
    name: Build Archive for ${{ matrix.workflow }}
    needs: prepare
    if: ${{ needs.prepare.outputs.should_proceed == 'true' }}
    runs-on: ubuntu-latest
    timeout-minutes: 60
    strategy:
      matrix:
        workflow: ${{fromJson(needs.prepare.outputs.workflows)}}
      fail-fast: false
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.ref }}
          lfs: true

      - name: Install dependencies
        run: |
          sudo DEBIAN_FRONTEND=noninteractive apt-get update -qq && sudo apt-get install -y --no-install-recommends p7zip-full pigz zstd parallel xxhash
          [ -w /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor ] && echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
          sudo sysctl -w vm.dirty_ratio=80 vm.dirty_background_ratio=20 vm.dirty_expire_centisecs=12000 vm.swappiness=10 vm.vfs_cache_pressure=50 || true
          sudo sysctl -w net.core.somaxconn=65535 net.ipv4.tcp_max_syn_backlog=65535 || true

      - name: Create archive for ${{ matrix.workflow }}
        id: create_archive
        env:
          WORKFLOW_NAME: ${{ matrix.workflow }}
          MAX_SIZE: 2147483648
          ZSTD_CLEVEL: 19
          ZSTD_NBTHREADS: 0
        run: |
          set -euo pipefail
          declare -A DIR_MAP=( ["国家法律法规数据库"]="./国家法律法规数据库" ["新闻联播"]="./新闻联播" ["Ruleset"]="./Ruleset" )
          SOURCE_DIR="${DIR_MAP[$WORKFLOW_NAME]}"

          [[ -z "$SOURCE_DIR" ]] && { echo "Unknown workflow: $WORKFLOW_NAME"; exit 1; }

          ARCHIVE_NAME="${WORKFLOW_NAME}.tar.zst"
          echo "Creating compressed archive for $WORKFLOW_NAME from $SOURCE_DIR"
          echo "Archive name will be: $ARCHIVE_NAME"

          [[ -d "$SOURCE_DIR" ]] || { echo "Source directory $SOURCE_DIR not found"; exit 1; }

          SOURCE_DIR_DIRNAME="$(dirname "$SOURCE_DIR")"
          SOURCE_DIR_BASENAME="$(basename "$SOURCE_DIR")"

          ionice -c 2 -n 0 nice -n -20 tar --use-compress-program="pigz -1" -cf - -C "$SOURCE_DIR_DIRNAME" "$SOURCE_DIR_BASENAME" | \
            ionice -c 2 -n 0 nice -n -20 zstd -T$ZSTD_NBTHREADS -$ZSTD_CLEVEL --ultra --long=31 --adapt=min=16,max=19 --no-progress - -o "$ARCHIVE_NAME"

          ARCHIVE_SIZE=$(stat -c%s "$ARCHIVE_NAME")
          echo "Compressed archive size: $ARCHIVE_SIZE bytes"

          if (( ARCHIVE_SIZE > MAX_SIZE )); then
            echo "Compressed archive exceeds size limit, applying splitting strategy"

            TEMP_DIR=$(mktemp -d)
            trap 'rm -rf "$TEMP_DIR"' EXIT INT TERM HUP

            original_hash=$(xxh64sum "$ARCHIVE_NAME" | cut -d" " -f1)
            original_size=$ARCHIVE_SIZE

            echo "Processing: $ARCHIVE_NAME ($original_size bytes)"
            split_dir="${WORKFLOW_NAME}_split"
            mkdir -p "$split_dir"

            manifest="$split_dir/manifest.txt"
            {
              echo "Original file: $ARCHIVE_NAME"
              echo "Original size: $original_size bytes"
              echo "Original xxHash: $original_hash"
              echo "Split timestamp: $(date -u +"%Y-%m-%dT%H:%M:%SZ")"
              echo "Parts:"
            } > "$manifest"

            split -b 1900M --numeric-suffixes=1 --suffix-length=2 "$ARCHIVE_NAME" "$TEMP_DIR/${WORKFLOW_NAME}_"

            find "$TEMP_DIR" -name "${WORKFLOW_NAME}_*" -type f -print0 | sort -z |
            while IFS= read -r -d '' part; do
              part_basename=$(basename "$part")
              part_name="${part_basename}.tar.zst"
              part_hash=$(xxh64sum "$part" | cut -d" " -f1)

              ionice -c 2 -n 0 cp --reflink=auto --sparse=always "$part" "$split_dir/$part_name"
              verify_hash=$(xxh64sum "$split_dir/$part_name" | cut -d" " -f1)

              if [[ "$part_hash" != "$verify_hash" ]]; then
                echo "ERROR: Hash verification failed for $part_name" >&2
                exit 1
              fi

              echo "$part_name: $part_hash (split part)" >> "$manifest"
            done

            shred -u "$ARCHIVE_NAME" 2>/dev/null || rm -f "$ARCHIVE_NAME"
            echo "ARCHIVE_PATH=${split_dir}" >> $GITHUB_OUTPUT
            echo "::notice::Archive split into multiple parts due to size constraints"
          else
            echo "ARCHIVE_PATH=${ARCHIVE_NAME}" >> $GITHUB_OUTPUT
          fi

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.workflow }}
          path: ${{ steps.create_archive.outputs.ARCHIVE_PATH }}
          retention-days: 1
          compression-level: 0

  publish:
    name: Publish Release
    needs: [prepare, build]
    runs-on: ubuntu-latest
    timeout-minutes: 60
    permissions:
      contents: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.ref }}

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./artifacts

      - name: Verify artifacts
        run: |
          set -euo pipefail
          declare -a workflows=("国家法律法规数据库" "新闻联播" "Ruleset")
          missing=0

          for workflow in "${workflows[@]}"; do
            artifact_dir="./artifacts/${workflow}"
            if [[ ! -d "$artifact_dir" ]]; then
              echo "::error::Missing artifact directory for ${workflow}"
              missing=$((missing + 1))
              continue
            fi

            if [[ -z "$(find "$artifact_dir" -type f 2>/dev/null)" ]]; then
              echo "::error::No files found in artifact directory for ${workflow}"
              missing=$((missing + 1))
            fi
          done

          if [[ $missing -gt 0 ]]; then
            echo "::error::${missing} required artifacts are missing. Cannot proceed with release."
            exit 1
          fi

          echo "All required artifacts are present."

      - name: Prepare files for release
        run: |
          set -euo pipefail
          mkdir -p ./release-files

          declare -a workflows=("国家法律法规数据库" "新闻联播" "Ruleset")

          exec {fd_log}>&1

          for workflow in "${workflows[@]}"; do
            artifact_dir="./artifacts/${workflow}"
            [[ ! -d "$artifact_dir" ]] && continue

            ascii_name=""
            case "$workflow" in
              "国家法律法规数据库") ascii_name="National-Database-of-Laws-and-Regulations" ;;
              "新闻联播") ascii_name="Xinwen-Lianbo" ;;
              "Ruleset") ascii_name="Ruleset" ;;
            esac

            find "$artifact_dir" -type f -name "*.tar.zst" -print0 |
            while IFS= read -r -d '' file; do
              if [[ -n "$ascii_name" && "$workflow" != "Ruleset" ]]; then
                cp -a --reflink=auto --sparse=always "$file" "./release-files/${ascii_name}.tar.zst"
              else
                cp -a --reflink=auto --sparse=always "$file" "./release-files/"
              fi
            done

            split_dir="$artifact_dir/${workflow}_split"
            if [[ -d "$split_dir" ]]; then
              if [[ -f "$split_dir/manifest.txt" ]]; then
                if [[ -n "$ascii_name" && "$workflow" != "Ruleset" ]]; then
                  cp -a --reflink=auto "$split_dir/manifest.txt" "./release-files/${ascii_name}_manifest.txt"
                else
                  cp -a --reflink=auto "$split_dir/manifest.txt" "./release-files/${workflow}_manifest.txt"
                fi
              fi

              find "$split_dir" -name "${workflow}_*.tar.zst" -type f -print0 |
              LC_ALL=C sort -z |
              while IFS= read -r -d '' src; do
                basename_src=$(basename "$src")

                if [[ -n "$ascii_name" && "$workflow" != "Ruleset" ]]; then
                  dst_name="${basename_src//${workflow}_/${ascii_name}_}"
                  dst="./release-files/$dst_name"
                else
                  dst="./release-files/$(basename "$src")"
                fi

                cp -a --reflink=auto --sparse=always "$src" "$dst"
              done
            fi
          done

          echo "Files to be uploaded:"
          find ./release-files -type f -print0 | LC_ALL=C sort -z | xargs -0 -n1 basename

      - name: Generate release notes
        id: generate_notes
        run: |
          {
            echo "## Recent commits"
            echo ""
            git -c log.showSignature=false log --pretty=format:"* %s (%h)" --since="24 hours ago" --no-merges
          } > release_notes.md

      - name: Create Release
        uses: softprops/action-gh-release@v2.3.2
        with:
          tag_name: v${{ needs.prepare.outputs.year }}.${{ needs.prepare.outputs.month }}.${{ needs.prepare.outputs.day }}
          name: ${{ needs.prepare.outputs.date }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          generate_release_notes: false
          make_latest: true
          files: |
            ./release-files/*
          fail_on_unmatched_files: false
